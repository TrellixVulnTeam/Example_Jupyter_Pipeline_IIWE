{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "<img src=\"AzPTravel_PPM.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GPM Data Transformation Script\n",
    "\n",
    "#### This script transforms the single consolidated raw file \"{Data Collection}.csv\" into it's final GPM input versions \"{Data Collection Code}localcur.csv\" and \"{Data Collection Code}euroconv.csv\"\n",
    "#### Current transformations\n",
    "\n",
    "-    make headers lowercase and replace spaces with hyphens\n",
    "-    Remove any rows with null BUs\n",
    "-    validate columns in validcols\n",
    "-    output documented here: \"Global_Attribute_Catalog.xlsx\" you can also edit dataframe entries using the instructions in the file\n",
    "-    replace various null or placeholder values with \"Not Provided\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "commit = \"\"\n",
    "# give a reason for the run\n",
    "\n",
    "percode = \"20XX.QX\"\n",
    "# Data Collection Code, this controls file paths and output names\n",
    "\n",
    "run_type = 1\n",
    "#run_type =  0 - lite run with no reporting, not recommended.\n",
    "#run_type =  1 - lite run with normal reporting, default setting.\n",
    "#run_type =  2 - Heavy run with full reporting, available for audits and troubleshooting.\n",
    "\n",
    "specialchars = \"-GTHtest\"\n",
    "# optional - add up to a 12 character code in order to mark your instance record .ipynb\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "inst_datetime = datetime.now().strftime(\"%m%d%Y%H%M%S\")\n",
    "# a single datetime stamp for the full instance run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Run Control\n",
    "\n",
    "##### 0 - lite run with no reporting, not recommended.\n",
    "##### 1 - lite run with normal reporting, default setting.\n",
    "##### 2 - Heavy run with full reporting, available for audits and troubleshooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_control = 0  # in development mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### Packages used\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from numpy import nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "default_dc = \"2021.Q1\"\n",
    "\n",
    "try:\n",
    "    if sys.argv[1] == \"-f\":\n",
    "        percode = default_dc\n",
    "    else:\n",
    "        percode = sys.argv[1]\n",
    "\n",
    "except IndexError:\n",
    "    percode = default_dc\n",
    "except NameError:\n",
    "    percode = default_dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert paths and files to variables.\n",
    "#### Read data into pd DataFrames.\n",
    "#### Make paths for the live sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rt_path = f'//hecate/Insurance_US/Product Development/Product Management/Global PPM/Reporting/Data Collection/Production/{str(percode)}'\n",
    "\n",
    "infile = os.path.join(rt_path, f'{str(percode)}.csv')\n",
    "gppm_file = os.path.join(rt_path, f'GPPM_Input_{str(percode)}.xlsx')\n",
    "atcat = f'//hecate/Insurance_US/Product Development/Product Management/Global PPM/Reporting/Data Collection/Production/{str(percode)}\\\\{str(percode)}_Attribute_Catalog.xlsx'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"this reads the consolidated file that will be transformed\"\"\"\n",
    "input = pd.read_csv(infile, low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a copy for debug purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trandata = input.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save the column names to variable, format them, replace headers\n",
    "cols = trandata.columns.values\n",
    "\n",
    "\"\"\"format headers\"\"\"\n",
    "fixedcols = []\n",
    "\n",
    "for f in cols:\n",
    "    fixedhead = f.replace(' ', '_').lower()\n",
    "    fixedcols.append(fixedhead)\n",
    "\n",
    "trandata.columns = fixedcols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Update Verification 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Original                                                                   | Transformed                                                                |\n",
      "|---:|:---------------------------------------------------------------------------|:---------------------------------------------------------------------------|\n",
      "|  0 | Business Unit                                                              | business_unit                                                              |\n",
      "|  1 | Country                                                                    | country                                                                    |\n",
      "|  2 | Currency                                                                   | currency                                                                   |\n",
      "|  3 | Region                                                                     | region                                                                     |\n",
      "|  4 | Reporting Date From                                                        | reporting_date_from                                                        |\n",
      "|  5 | Reporting Date To                                                          | reporting_date_to                                                          |\n",
      "|  6 | Date of Analysis                                                           | date_of_analysis                                                           |\n",
      "|  7 | Type of Analysis                                                           | type_of_analysis                                                           |\n",
      "|  8 | Analysed Months                                                            | analysed_months                                                            |\n",
      "|  9 | Reporting Year                                                             | reporting_year                                                             |\n",
      "| 10 | Reporting Quarter                                                          | reporting_quarter                                                          |\n",
      "| 11 | Reporting Month                                                            | reporting_month                                                            |\n",
      "| 12 | Type of Business                                                           | type_of_business                                                           |\n",
      "| 13 | Type of Account                                                            | type_of_account                                                            |\n",
      "| 14 | Distribution Type                                                          | distribution_type                                                          |\n",
      "| 15 | LOB                                                                        | lob                                                                        |\n",
      "| 16 | Distribution Channel                                                       | distribution_channel                                                       |\n",
      "| 17 | Sub LOB                                                                    | sub_lob                                                                    |\n",
      "| 18 | Business Partner Name                                                      | business_partner_name                                                      |\n",
      "| 19 | Business Partner ID Number                                                 | business_partner_id_number                                                 |\n",
      "| 20 | Product Name                                                               | product_name                                                               |\n",
      "| 21 | Product ID Number                                                          | product_id_number                                                          |\n",
      "| 22 | Product Family                                                             | product_family                                                             |\n",
      "| 23 | Standard Product                                                           | standard_product                                                           |\n",
      "| 24 | Number of Products per Row                                                 | number_of_products_per_row                                                 |\n",
      "| 25 | Number of B-Partners per Row                                               | number_of_b-partners_per_row                                               |\n",
      "| 26 | Number of Policies (Written)                                               | number_of_policies_(written)                                               |\n",
      "| 27 | Units of Risk (Written)                                                    | units_of_risk_(written)                                                    |\n",
      "| 28 | Written Revenues net of Taxes                                              | written_revenues_net_of_taxes                                              |\n",
      "| 29 | Written Revenues                                                           | written_revenues                                                           |\n",
      "| 30 | Number of Policies (Earned)                                                | number_of_policies_(earned)                                                |\n",
      "| 31 | Units of Risk (Earned)                                                     | units_of_risk_(earned)                                                     |\n",
      "| 32 | Earned Revenues net of Taxes                                               | earned_revenues_net_of_taxes                                               |\n",
      "| 33 | Earned Revenues                                                            | earned_revenues                                                            |\n",
      "| 34 | Earned Base Commissions                                                    | earned_base_commissions                                                    |\n",
      "| 35 | Earned Over-Commissions                                                    | earned_over-commissions                                                    |\n",
      "| 36 | Upfront Cash Payments                                                      | upfront_cash_payments                                                      |\n",
      "| 37 | Total Compensation                                                         | total_compensation                                                         |\n",
      "| 38 | Number of Claims (Paid + OCR + IBNR)                                       | number_of_claims_(paid_+_ocr_+_ibnr)                                       |\n",
      "| 39 | Number of Open Claims                                                      | number_of_open_claims                                                      |\n",
      "| 40 | Open Claims %                                                              | open_claims_%                                                              |\n",
      "| 41 | Number of Persons Involved in Claims (Paid + OCR + IBNR)                   | number_of_persons_involved_in_claims_(paid_+_ocr_+_ibnr)                   |\n",
      "| 42 | Paid Claims                                                                | paid_claims                                                                |\n",
      "| 43 | OCR + IBNR                                                                 | ocr_+_ibnr                                                                 |\n",
      "| 44 | Actual Incurred Losses (Paid + OCR + IBNR)                                 | actual_incurred_losses_(paid_+_ocr_+_ibnr)                                 |\n",
      "| 45 | Internal Variable Costs (excl. AZ Tech Fee)                                | internal_variable_costs_(excl._az_tech_fee)                                |\n",
      "| 46 | AZ Tech Fee                                                                | az_tech_fee                                                                |\n",
      "| 47 | Internal Fixed Costs (excl. HQ Fees)                                       | internal_fixed_costs_(excl._hq_fees)                                       |\n",
      "| 48 | HQ Fees                                                                    | hq_fees                                                                    |\n",
      "| 49 | Total Expenses                                                             | total_expenses                                                             |\n",
      "| 50 | Frequency (Earned)                                                         | frequency_(earned)                                                         |\n",
      "| 51 | Severity                                                                   | severity                                                                   |\n",
      "| 52 | Risk Premium                                                               | risk_premium                                                               |\n",
      "| 53 | Contribution Margin - BU View                                              | contribution_margin_-_bu_view                                              |\n",
      "| 54 | Contribution Margin % on Fixed Costs - BU View                             | contribution_margin_%_on_fixed_costs_-_bu_view                             |\n",
      "| 55 | Contribution Margin % on Earned Revenues net of Taxes - BU View            | contribution_margin_%_on_earned_revenues_net_of_taxes_-_bu_view            |\n",
      "| 56 | Contribution Margin - HQ View                                              | contribution_margin_-_hq_view                                              |\n",
      "| 57 | Contribution Margin % on Fixed Costs - HQ View                             | contribution_margin_%_on_fixed_costs_-_hq_view                             |\n",
      "| 58 | Contribution Margin % on Earned Revenues net of Taxes - HQ View            | contribution_margin_%_on_earned_revenues_net_of_taxes_-_hq_view            |\n",
      "| 59 | Loss Ratio                                                                 | loss_ratio                                                                 |\n",
      "| 60 | Commission Ratio                                                           | commission_ratio                                                           |\n",
      "| 61 | Expense Ratio                                                              | expense_ratio                                                              |\n",
      "| 62 | Combined Ratio                                                             | combined_ratio                                                             |\n",
      "| 63 | Profit or Loss                                                             | profit_or_loss                                                             |\n",
      "| 64 | Notes                                                                      | notes                                                                      |\n",
      "| 65 | Notes - Operating Profit with additional unearned premiums due to COVID-19 | notes_-_operating_profit_with_additional_unearned_premiums_due_to_covid-19 |\n",
      "| 66 | Unnamed: 65                                                                | unnamed:_65                                                                |\n",
      "| 67 | concat2                                                                    | concat2                                                                    |\n",
      "| 68 | comsub                                                                     | comsub                                                                     |\n",
      "| 69 | expsub                                                                     | expsub                                                                     |\n",
      "| 70 | Reporting Date From INT                                                    | reporting_date_from_int                                                    |\n",
      "| 71 | Reporting Date To INT                                                      | reporting_date_to_int                                                      |\n",
      "| 72 | Date of Analysis INT                                                       | date_of_analysis_int                                                       |\n",
      "| 73 | Selected Fields for Duplicates                                             | selected_fields_for_duplicates                                             |\n",
      "| 74 | Identifier to pull in results from Data tab                                | identifier_to_pull_in_results_from_data_tab                                |\n",
      "| 75 | Unnamed: 66                                                                | unnamed:_66                                                                |\n",
      "| 76 | Unnamed: 67                                                                | unnamed:_67                                                                |\n"
     ]
    }
   ],
   "source": [
    "if run_control > -10:\n",
    "    disp = {\"Original\": input.columns, \"Transformed\": trandata.columns}\n",
    "\n",
    "    disp = pd.DataFrame(disp)\n",
    "\n",
    "    print(disp.to_markdown())\n",
    "else:\n",
    "    print(\"Skipped Transformation Report 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rows with null business units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# todo, remove this from read file\n",
    "trandata = trandata[trandata.business_unit.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update Verification 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Counts\n",
      "|    | Business Unit   |   Original |   Transformed |\n",
      "|---:|:----------------|-----------:|--------------:|\n",
      "|  0 | AT              |        583 |           583 |\n",
      "|  1 | AU              |         85 |            85 |\n",
      "|  2 | CA              |         44 |            44 |\n",
      "|  3 | CH              |       1810 |          1810 |\n",
      "|  4 | CN              |         49 |            49 |\n",
      "|  5 | DE              |        150 |           150 |\n",
      "|  6 | ES              |         55 |            55 |\n",
      "|  7 | FOS             |         63 |            63 |\n",
      "|  8 | FR              |        442 |           442 |\n",
      "|  9 | GR              |         17 |            17 |\n",
      "| 10 | IT              |        100 |           100 |\n",
      "| 11 | NB              |         62 |            62 |\n",
      "| 12 | NL              |        173 |           173 |\n",
      "| 13 | NZ              |         41 |            41 |\n",
      "| 14 | PL              |         31 |            31 |\n",
      "| 15 | PT              |         67 |            67 |\n",
      "| 16 | UK              |        594 |           594 |\n",
      "| 17 | US              |      11359 |         11359 |\n"
     ]
    }
   ],
   "source": [
    "if run_control > -10:\n",
    "\n",
    "    ibus = input.groupby(['Business Unit']).count()\n",
    "    ibus = ibus.reset_index()\n",
    "    tbus = trandata.groupby(['business_unit']).count()\n",
    "    tbus = tbus.reset_index()\n",
    "\n",
    "    compdata = pd.merge(ibus, tbus, left_on='Business Unit', right_on='business_unit', how='left')\n",
    "\n",
    "    disp = {\"Business Unit\": compdata['Business Unit'], \"Original\": compdata['Earned Revenues net of Taxes'],\n",
    "            \"Transformed\": compdata['earned_revenues_net_of_taxes']}\n",
    "\n",
    "    disp = pd.DataFrame(disp)\n",
    "\n",
    "    print(\"Row Counts\")\n",
    "    print(disp.to_markdown())\n",
    "else:\n",
    "    print(\"Skipped Transformation Report 2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swap  nulls for \"Not Provided\" in 'Sub Lob' and 'Distribution Channel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mults = trandata['sub_lob'][trandata.sub_lob.replace(nan, 'Not Provided').str.contains(',', case=False)]\n",
    "mults = mults.unique()\n",
    "\n",
    "trandata['sub_lob'] = trandata['sub_lob'].fillna('Not Provided')\n",
    "trandata['sub_lob'] = trandata['sub_lob'].replace('', 'Not Provided')\n",
    "trandata['distribution_channel'] = trandata['distribution_channel'].replace('', 'Not Provided').fillna('Not Provided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace multiple entries in \"Sub Lob\" to \"Multiple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in mults:\n",
    "    trandata['sub_lob'] = trandata['sub_lob'].replace(i, 'Multiple')\n",
    "\n",
    "# todo automate figuring out which fields fx rates should be applied to somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update Verification 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if run_control > -10:\n",
    "\n",
    "    ibus = input.groupby(['Sub LOB']).sum()\n",
    "    ibus = ibus.reset_index()\n",
    "    tbus = trandata.groupby(['sub_lob']).sum()\n",
    "    tbus = tbus.reset_index()\n",
    "\n",
    "    compdatasublob = pd.merge(ibus, tbus, left_on='Sub LOB', right_on='sub_lob', how='outer')\n",
    "\n",
    "    disp1 = pd.DataFrame(\n",
    "        {'Original Sub LOB': compdatasublob['Sub LOB'], 'Transformed Sub LOB': compdatasublob['sub_lob'],\n",
    "         \"Original\": compdatasublob['Earned Revenues net of Taxes'] / 1000,\n",
    "         \"Transformed\": compdatasublob['earned_revenues_net_of_taxes'] / 1000})\n",
    "\n",
    "\n",
    "\n",
    "    tots1 = pd.DataFrame({'Original Total': (input['Earned Revenues net of Taxes']).sum() / 10000,\n",
    "                          \"Transformed Total\": (compdatasublob['earned_revenues_net_of_taxes']).sum() / 10000},\n",
    "                         index=[0])\n",
    "else:\n",
    "    print(\"Skipped Transformation Report 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make cflds, a list of currency fields, force to float, coercion is null or string to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cflds = ['written_revenues_net_of_taxes', 'written_revenues', 'earned_revenues_net_of_taxes',\n",
    "         'earned_revenues', 'earned_base_commissions', 'earned_over-commissions', 'upfront_cash_payments',\n",
    "         'total_compensation', 'paid_claims', 'ocr_+_ibnr', 'actual_incurred_losses_(paid_+_ocr_+_ibnr)',\n",
    "         'internal_variable_costs_(excl._az_tech_fee)', 'az_tech_fee', 'internal_fixed_costs_(excl._hq_fees)',\n",
    "         'hq_fees', 'total_expenses', 'risk_premium', 'profit_or_loss', 'contribution_margin_-_hq_view',\n",
    "         'contribution_margin_-_bu_view', ]\n",
    "\n",
    "for i in cflds:\n",
    "    pd.to_numeric(trandata[i], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn selected columns values uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "validcols = ['business_unit', 'currency', 'region', 'type_of_analysis', 'type_of_business', 'type_of_account', 'lob',\n",
    "             'distribution_type', 'distribution_channel', ]\n",
    "\n",
    "for c in validcols:\n",
    "    trandata[c] = trandata[c].astype(str)\n",
    "    trandata[c] = trandata[c].apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the values from the Global Attribute Catalog, one field per loop iterance and xlsx sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checktabs = []\n",
    "\n",
    "\n",
    "\n",
    "for s in validcols:\n",
    "    t = pd.read_excel(atcat, sheet_name = s )\n",
    "    checktabs.append([[s], [t]])\n",
    "\n",
    "gacout = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the lists from the previous step and each field. Find those that do not match, make lists of unique values\n",
    "#### replace any that have replacements in GPPM inoout already, make a list of values without any matches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for u in enumerate(validcols):\n",
    "    trandata.loc[0:len(trandata[u[1]]), u[1]] = trandata[u[1]].replace(\n",
    "        [checktabs[u[0]][1][0]['Upper_Vers']][0].to_numpy(), [checktabs[u[0]][1][0][u[1]]][0].to_numpy())\n",
    "    d = list(checktabs[u[0]][1][0]['Non Matches'].drop_duplicates().dropna().append(\n",
    "        pd.Series(trandata[u[1]][~trandata[u[1]].isin(checktabs[u[0]][1][0][u[1]])].drop_duplicates().dropna()),\n",
    "        ignore_index=True))\n",
    "    g = [checktabs[u[0]][1][0][str(u[1])], checktabs[u[0]][1][0]['Upper_Vers'], checktabs[u[0]][1][0]['Unnamed: 2'],\n",
    "         pd.Series(d, dtype='object').drop_duplicates().dropna(), checktabs[u[0]][1][0]['User Defined Corrections']]\n",
    "    gacout.append(list([g, u[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebuild the GPPM input file, with the replaced values in the bad values column of each sheet.\n",
    "#### Step one, make and xlsx with a notes page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w = ExcelWriter(atcat)\n",
    "notes = pd.DataFrame([\n",
    "    \"This page is script generated during the source creation process. Do not edit these notes directly in the file as they will be overwritten\",\n",
    "    \"\", \"\"\n",
    "    , \" Purpose :     to manage attribute entries in the data collection process, this workbook documents and organizes all entries and also allows a user to swap those that do \\\n",
    "                        not conform to validation rules  with an entry of their choice\",\n",
    "    \" Each attribute field that requires validation has its own sheet tab\", \"\"\n",
    "    , \"Column A:    of each sheet tab contains all unique acceptable responses\",\n",
    "    \"Column B:    an upper case version, to wrangle case mismatches\",\n",
    "    \"Column D:   is generated by the process, this is a list of an uppercase version of each unique unacceptable response, this builds over time with each collection\",\n",
    "    \"Column E:   you can enter accpetable response here (sase sensitive) to be swapped out in the data, save and exit this file, run the process again and they will be replaced\"\n",
    "    , \"\", \"\", \"Gavin Harmon 9 - July -2020\"])\n",
    "\n",
    "notes.columns = ['Notes']\n",
    "\n",
    "notes.to_excel(w, index=False, sheet_name=\"Notes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step two, build the new sheets for each validcols field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for v in enumerate(validcols):\n",
    "    df = pd.DataFrame(gacout[v[0]][0], index=[f\"{v[1]}\", 'Upper_Vers', '', 'Non Matches', 'User Defined Corrections']).T\n",
    "    df.to_excel(w, index=False, sheet_name=gacout[v[0]][1])\n",
    "w.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step three, read these lists back in, make the necessary replacements in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for s in validcols:\n",
    "    t = pd.read_excel(f'//hecate/Insurance_US/Product Development/Product Management/Global PPM/Reporting/Data Collection/Production/{str(percode)}\\\\{str(percode)}_Attribute_Catalog.xlsx', sheet_name = s )\n",
    "    checktabs.append([[s],[t]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gacout = []\n",
    "\n",
    "for u in enumerate(validcols):\n",
    "    trandata.loc[0:len(trandata[u[1]]), u[1]] = trandata[u[1]].replace(\n",
    "        [checktabs[u[0]][1][0]['Non Matches']][0].to_numpy(),\n",
    "        [checktabs[u[0]][1][0]['User Defined Corrections']][0].to_numpy())\n",
    "repper = trandata[['business_unit', 'reporting_date_to']]\n",
    "repper = pd.DataFrame({\"business_unit\": (repper['business_unit']), \"YearMo\": (repper['reporting_date_to'])})\n",
    "minrep = repper.groupby(['business_unit']).max()\n",
    "a = trandata['business_unit'].replace(list(minrep.axes[0]), minrep.get(\"YearMo\"))\n",
    "trandata['rep_date'] = a\n",
    "trandata.loc[0:len(trandata['business_partner_id_number']), 'business_partner_id_number'] = trandata[\n",
    "    'business_partner_id_number'].replace('0', 'Not Provided').fillna('Not Provided')\n",
    "trandata.loc[0:len(trandata['product_id_number']), 'product_id_number'] = trandata['product_id_number'].replace('0',\n",
    "                                                                                                                'Not Provided').replace(\n",
    "    '-', 'Not Provided').fillna('Not Provided')\n",
    "trandata.loc[0:len(trandata['sub_lob']), 'sub_lob'] = trandata['sub_lob'].replace('0', 'Not Provided').replace('-',\n",
    "                                                                                                               'Not Provided').replace(\n",
    "    'Other', 'Not Provided').fillna('Not Provided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove empty rows, if there is no claims experience and no revenue for a 12 month period, it should not be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trandata = trandata.loc[(trandata['units_of_risk_(written)'].fillna(0).replace('', 0)\n",
    "                         + trandata['written_revenues_net_of_taxes'].fillna(0).replace('', 0)\n",
    "                         + trandata['written_revenues'].fillna(0).replace('', 0)\n",
    "                         + trandata['number_of_policies_(earned)'].fillna(0).replace('', 0)\n",
    "                         + trandata['units_of_risk_(earned)'].fillna(0).replace('', 0)\n",
    "                         + trandata['earned_revenues_net_of_taxes'].fillna(0).replace('', 0)\n",
    "                         + trandata['earned_revenues'].fillna(0).replace('', 0)\n",
    "                         + trandata['earned_base_commissions'].fillna(0).replace('', 0)\n",
    "                         + trandata['upfront_cash_payments'].fillna(0).replace('', 0)\n",
    "                         + trandata['earned_over-commissions'].fillna(0).replace('', 0)\n",
    "                         + trandata['total_compensation'].fillna(0).replace('', 0)\n",
    "                         + trandata['number_of_claims_(paid_+_ocr_+_ibnr)'].fillna(0).replace('', 0)\n",
    "                         + trandata['number_of_open_claims'].fillna(0).replace('', 0)\n",
    "                         + trandata['open_claims_%'].fillna(0).replace('', 0)\n",
    "                         + trandata['number_of_persons_involved_in_claims_(paid_+_ocr_+_ibnr)'].fillna(0).replace('', 0)\n",
    "                         + trandata['paid_claims'].fillna(0).replace('', 0)\n",
    "                         + trandata['ocr_+_ibnr'].fillna(0).replace('', 0)\n",
    "                         + trandata['actual_incurred_losses_(paid_+_ocr_+_ibnr)'].fillna(0).replace('', 0)\n",
    "                         + trandata['internal_variable_costs_(excl._az_tech_fee)'].fillna(0).replace('', 0)\n",
    "                         + trandata['az_tech_fee'].fillna(0).replace('', 0)\n",
    "                         + trandata['internal_fixed_costs_(excl._hq_fees)'].fillna(0).replace('', 0)\n",
    "                         + trandata['hq_fees'].fillna(0).replace('', 0)\n",
    "                         + trandata['total_expenses'].fillna(0).replace('', 0)\n",
    "                         + trandata['frequency_(earned)'].fillna(0).replace('', 0)\n",
    "                         + trandata['severity'].fillna(0).replace('', 0))\n",
    "                        != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Output temp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trandata.to_parquet(\n",
    "    f'//hecate/Insurance_US/Product Development/Product Management/Global PPM/Reporting/Data Collection/Production/{str(percode)}\\\\{str(percode)}.localcur.parquet')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
