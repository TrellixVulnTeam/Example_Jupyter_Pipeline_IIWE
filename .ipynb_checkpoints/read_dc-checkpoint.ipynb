{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"AzPTravel_PPM.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Source File Consolidation\n",
    "\n",
    "#### This script fetches the current data collection submission files, consolidates them in to a combined csv file, and outputs that to the network.\n",
    "- All source files stored in the path are read, summarized, and then consolidated into a single dataframe named 'df'.\n",
    "- This process assumes that the multiple sources are in no way duplicates of each other.\n",
    "- df is then output in the data collection subfolder of the \"Production\" folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Variables\n",
    "- These are overwritten if inherited from run_control.ipynb.\n",
    "- Feel Free to reset them for a manual run if you like\n",
    "- Do not save without percode = \"-f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "commit_message = \"Development and testing.\"\n",
    "# Give a brief reason for the run.\n",
    "\n",
    "run_control = 1\n",
    "#run_type = 0 - Lite run with no reporting, not recommended.\n",
    "#run_type = 1 - Lite run with normal reporting, default setting.\n",
    "#run_type = 2 - Heavy run with full reporting, available for audits and troubleshooting.\n",
    "#run_type = 5 - A default setting. Indicates the script is being run by an outside process without an inherited value\n",
    "\n",
    "percode = \"2021.Q1\"\n",
    "# Data Collection Code, this controls file paths and output names\n",
    "# \"-f\" is the value indicating a bad inheritance from run with arg\n",
    "\n",
    "#----------\n",
    "# do not edit - this either inherits the full instance timestamp from the papermill book or captures the run time of this script.\n",
    "from datetime import datetime\n",
    "inst_datetime = datetime.now().strftime(\"%m%d%Y%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import getpass\n",
    "#### Packages used\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default Variables, these govern logic, do not edit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "default_dc = \"20XX.QX\"\n",
    "default_rc = 0 #extra lite mode\n",
    "dummy_perc = \"33Q3\" # bad inheritance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Script determining run context ie, manual, run_control.ipynb, or other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "if run_control == 5:\n",
    "    run_control = default_rc \n",
    "else:\n",
    "    run_control = run_control\n",
    "\n",
    "try:\n",
    "    if sys.argv[1] == \"-f\":\n",
    "        percode = percode\n",
    "    else:\n",
    "        percode = sys.argv[1]\n",
    "\n",
    "except IndexError:\n",
    "    percode = default_dc\n",
    "except NameError:\n",
    "    percode = default_dc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### style settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Make paths for the source folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rt_path = f'//hecate/Insurance_US/Product Development/Product Management/Global PPM/Reporting/Data Collection/Production/{str(percode)}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Read each json file into temp DataFrame \"data\".\n",
    "- Prep actions - Strip (trim) leading and trailing spaces values in string columns, remove rows without business units.\n",
    "- Append each json output to into 1 DataFrame \"df\".\n",
    "- Process Cleanup, the indices restart with each append, reset and drop the previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prep_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9f18094312b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprepparq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrt_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"{percode}prep.parquet\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"pyarrow\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprepfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prep_file' is not defined"
     ]
    }
   ],
   "source": [
    "prepfile = os.path.join(str(rt_path), f\"{percode}prep.csv\")\n",
    "prepparq = os.path.join(str(rt_path), f\"{percode}prep.parquet\")\n",
    "\n",
    "df = pd.read_parquet(prepparq, engine = \"pyarrow\")\n",
    "\n",
    "os.remove(prepfile)\n",
    "os.remove(prepparq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Upload Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def num_format(x):\n",
    "    \"\"\"number format without a currency\"\"\"\n",
    "    return \"{:,.0f}\".format(x)\n",
    "\n",
    "if run_control > 0:\n",
    "\n",
    "    sumdata = df.groupby(['Business Unit']).sum()\n",
    "    sumdata = sumdata.reset_index()\n",
    "    plt.bar(sumdata['Business Unit'], sumdata['Earned Revenues net of Taxes']/1000)\n",
    "    plt.title('Earned Revenue net of Taxes by BU in thousands LC')\n",
    "    plt.show()\n",
    "\n",
    "    countdata = df.groupby(['Business Unit']).count()\n",
    "    countdata = countdata.reset_index()\n",
    "    plt.bar(countdata['Business Unit'], countdata['Earned Revenues net of Taxes'])\n",
    "    plt.title('Row Counts by BU')\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Charts Skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw files - extensive audit, best to skip unless troubleshooting, may crash a browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# setup for json only\n",
    "# if run_control > 1:\n",
    "#     for f in pathfiles:\n",
    "#         with open(f, 'r') as json_file:\n",
    "#             json_object = json.load(json_file)\n",
    "#         print(json.dumps(json_object, indent=1))\n",
    "#\n",
    "# else:\n",
    "#     print(\"Audit Report 1 Skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Processes\n",
    "- Define File names.\n",
    "- If existing csv is found, archive it in \"raw_data_file_history\" folder.\n",
    "- Save new csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file = f'{str(percode)}.csv'\n",
    "pfile = f'{str(percode)}.parquet'\n",
    "histfile = f'{str(percode)}_{inst_datetime}.csv'\n",
    "\n",
    "try:\n",
    "    os.rename(os.path.join(str(rt_path), file), os.path.join(str(rt_path), \"logs/raw_data_file_history/\" , histfile))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "df.to_csv(os.path.join(str(rt_path), file), ',', index=False , encoding='utf-8-sig')\n",
    "df.to_parquet(os.path.join(str(rt_path), pfile), engine = \"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Log update record with commit message and time.\n",
    "- Determine commit message and make new entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log = os.path.join(str(rt_path), f'logs/pipline_log.csv' )\n",
    "\n",
    "try:\n",
    "    log_df = pd.read_csv(log)\n",
    "except NameError:\n",
    "    print(\"No log file present\")\n",
    "\n",
    "# determine if running from notebook or Excel controller and set commit message.\n",
    "if sys.argv[1] == \"-f\":\n",
    "    message = commit_message\n",
    "else:\n",
    "    piperunner = '//hecate/Insurance_US/Product Development/Product Management/Global PPM/Reporting/_To' \\\n",
    "                 'ols/GitHub/Production Repositories/Pipeline Runner/Pipeline Runner.xlsm'\n",
    "    wb = openpyxl.load_workbook(piperunner)\n",
    "    sh = wb['Pipeline Runner']\n",
    "    message = sh['f13'].value\n",
    "\n",
    "# find username\n",
    "username = getpass.getuser()\n",
    "\n",
    "# record timestamp\n",
    "datetime = inst_datetime\n",
    "dateformat = datetime[4:8] + '-' + datetime[:2]  + '-' + datetime[2:4]  + '-' + datetime[8:]\n",
    "\n",
    "# add new line\n",
    "newline = { \"run_message\" : [message ],  \"datetime\" :[dateformat], \"user\" : [username ]}\n",
    "newline = pd.DataFrame.from_dict(newline)\n",
    "\n",
    "# make new file\n",
    "log_df = log_df.append(newline[0:])\n",
    "log_df\n",
    "log_df.to_csv(log, ',', index=False , encoding='utf-8-sig')\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
