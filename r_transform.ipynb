{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal R file for Proof of Concept\n",
    "### To be built into all trasformations from the Travel Global Report\n",
    "### Adapted from Travel_Global_Report_Pipeline_Version.Rmd with all Python code removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "commit <- \"New German Data.\"\n",
    "# give a reason for the run\n",
    "\n",
    "percode <- \"2021.Q1\"\n",
    "# Data Collection Code, this controls file paths and output names\n",
    "\n",
    "run_type <- 1\n",
    "#run_type =  0 - lite run with no reporting, not recommended.\n",
    "#run_type =  1 - lite run with normal reporting, default setting.\n",
    "#run_type =  2 - Heavy run with full reporting, available for audits and troubleshooting.\n",
    "\n",
    "specialchars <- \"-GTHtest\"\n",
    "# optional - add up to a 12 character code in order to mark your instance record .ipynb\n",
    "\n",
    "#inst_datetime <- datetime.now().strftime(\"%m%d%Y%H%M%S\")\n",
    "# a single datetime stamp for the full instance run\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'arrow' was built under R version 3.6.3\"See arrow_info() for available features\n",
      "\n",
      "Attaching package: 'arrow'\n",
      "\n",
      "The following object is masked from 'package:utils':\n",
      "\n",
      "    timestamp\n",
      "\n",
      "Warning message:\n",
      "\"package 'openxlsx' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'data.table' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'dplyr' was built under R version 3.6.3\"Registered S3 methods overwritten by 'tibble':\n",
      "  method     from  \n",
      "  format.tbl pillar\n",
      "  print.tbl  pillar\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following objects are masked from 'package:data.table':\n",
      "\n",
      "    between, first, last\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "Warning message:\n",
      "\"package 'magrittr' was built under R version 3.6.3\"\n",
      "Attaching package: 'magrittr'\n",
      "\n",
      "The following object is masked from 'package:arrow':\n",
      "\n",
      "    is_in\n",
      "\n",
      "Warning message:\n",
      "\"package 'knitr' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'kableExtra' was built under R version 3.6.3\"\n",
      "Attaching package: 'kableExtra'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    group_rows\n",
      "\n",
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'patchwork' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'DT' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'scales' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'stringr' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'arsenal' was built under R version 3.6.3\"\n",
      "Attaching package: 'arsenal'\n",
      "\n",
      "The following object is masked from 'package:scales':\n",
      "\n",
      "    ordinal\n",
      "\n",
      "The following object is masked from 'package:magrittr':\n",
      "\n",
      "    set_attr\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Optional ultimately maybe parameterize if people need libs installed.\n",
    "\n",
    "# install.packages(\"arrow\")\n",
    "# install.packages(\"openxlsx\") # excel\n",
    "# install.packages(\"data.table\") # data manipulation\n",
    "# install.packages(\"dplyr\") # data manipulation used in some of the viz\n",
    "# install.packages(\"magrittr\") # chaining\n",
    "# install.packages(\"knitr\") # html table output with kable function\n",
    "# install.packages(\"kableExtra\") # addtl styling to kable tables\n",
    "# install.packages(\"ggplot2\") # visualization\n",
    "# install.packages(\"patchwork\") # viz, combine plots in one image\n",
    "# install.packages(\"DT\") # html table output (javascript)\n",
    "# install.packages(\"scales\") # plot scales\n",
    "# install.packages(\"stringr\") # string replace\n",
    "# install.packages(\"arsenal\") # comparison functionality\n",
    "\n",
    "\n",
    "\n",
    "#----- Libraries ------\n",
    "\n",
    "library(arrow) # read/write parquet\n",
    "library(openxlsx) # excel\n",
    "library(data.table) # data manipulation\n",
    "library(dplyr) # data manipulation used in some of the viz\n",
    "library(magrittr) # chaining\n",
    "library(knitr) # html table output with kable function\n",
    "library(kableExtra) # addtl styling to kable tables\n",
    "library(ggplot2) # visualization\n",
    "library(patchwork) # viz, combine plots in one image\n",
    "library(DT) # html table output (javascript)\n",
    "library(scales) # plot scales\n",
    "library(stringr) # string replace\n",
    "library(arsenal) # comparison functionality\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read parquet file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_path <- file.path('//hecate/Insurance_US/Product Development/Product Management/Global PPM/Reporting/Data Collection/Production', percode )\n",
    "\n",
    "tempfile <- file.path(rt_path,'2021.Q1.localcur.parquet' )\n",
    "\n",
    "pq_input <-  read_parquet( tempfile,  col_select = NULL,\n",
    "  as_data_frame = TRUE,  props = ParquetArrowReaderProperties$create())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original data input section, some adaptations for i_bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in read.xlsx.default(xlsxFile = file.path(data_dir, inputs), sheet = \"Euro_Rates\"): Cannot find sheet named \"Euro_Rates\"\n",
     "output_type": "error",
     "traceback": [
      "Error in read.xlsx.default(xlsxFile = file.path(data_dir, inputs), sheet = \"Euro_Rates\"): Cannot find sheet named \"Euro_Rates\"\nTraceback:\n",
      "1. as.data.table(read.xlsx(xlsxFile = file.path(data_dir, inputs), \n .     sheet = \"Euro_Rates\"))",
      "2. read.xlsx(xlsxFile = file.path(data_dir, inputs), sheet = \"Euro_Rates\")",
      "3. read.xlsx.default(xlsxFile = file.path(data_dir, inputs), sheet = \"Euro_Rates\")",
      "4. stop(sprintf(\"Cannot find sheet named \\\"%s\\\"\", sheet))"
     ]
    }
   ],
   "source": [
    "\n",
    "# source('ColorPalette.R')\n",
    "\n",
    "#----- Data ------\n",
    "\n",
    "# define data directory\n",
    "data_dir <- rt_path\n",
    "\n",
    "\n",
    "\n",
    "# read in BU datasets\n",
    "# data has been pre-processed and already converted to one currency (euro)\n",
    "#d_input <- fread(file.path(data_dir, '2020.Q4.euroconv.csv'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read in dataset for reference items\n",
    "# file for inputs\n",
    "inputs <- paste(\"GPPM_Input_\",percode,\".xlsx\",sep=\"\")\n",
    "\n",
    "# read in Euro exchange rates\n",
    "# !!! use rates as of the end of the reporting period\n",
    "# From Az Connect, https://connect.allianz.com/docs/DOC-220762\n",
    "i_rates <- as.data.table(\n",
    "  read.xlsx(\n",
    "    xlsxFile = file.path(data_dir, inputs), \n",
    "    sheet = 'Euro_Rates'\n",
    "    )\n",
    "  )\n",
    "\n",
    "i_def <- as.data.table(read.xlsx(\n",
    "  xlsxFile = file.path(data_dir, inputs), \n",
    "  sheet = 'Definitions', \n",
    "  startRow = 1\n",
    "  )\n",
    ")\n",
    "names(i_def)[names(i_def) == 'Data.Type'] <- 'Data Type' # quick way (base R) to replace the \".\" in Data Type header\n",
    "\n",
    "i_bu <- as.data.table(\n",
    "  read.xlsx(\n",
    "  xlsxFile = file.path(data_dir, inputs), \n",
    "  sheet = 'BU_Descr', \n",
    "  startRow = 1\n",
    "  )\n",
    ")\n",
    "\n",
    "#create R object from py variable\n",
    "\n",
    "d_input <- as.data.table(pq_input)\n",
    "\n",
    "print(d_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data manipulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all NAs with 0\n",
    "# stolen from https://stackoverflow.com/questions/7235657/fastest-way-to-replace-nas-in-a-large-data-table\n",
    "replaceNA <- function(dt, replace = 0) {\n",
    "  for (j in seq_len(ncol(dt)))\n",
    "    set(dt, which(is.na(dt[[j]])), j , replace)\n",
    "}\n",
    "\n",
    "# Rename columns to make easier to work with in a function\n",
    "# Replace \".\"s with \"_\"s & make lower case\n",
    "# replace other patterns not needed in description\n",
    "fixNames <- function(columns) {\n",
    "  columns <- columns %>%\n",
    "    tolower() %>% \n",
    "    gsub(pattern = '.', replacement = '_', fixed = TRUE) %>% \n",
    "    gsub(pattern = '_(paid_+_ocr_+_ibnr)', replacement = '', fixed = TRUE) %>%\n",
    "    gsub(pattern = '_(excl__az_tech_fee)', replacement = '', fixed = TRUE) %>%\n",
    "    gsub(pattern = '_(excl__hq_fees)', replacement = '', fixed = TRUE) %>%\n",
    "    gsub(pattern = 'persons_involved_in_claims', replacement = 'claimants', fixed = TRUE) %>%\n",
    "    gsub(pattern = 'units_of_risk', replacement = 'insureds', fixed = TRUE) %>%\n",
    "    gsub(pattern = 'contribution_margin', replacement = 'cm', fixed = TRUE) %>%\n",
    "    gsub(pattern = 'number_of', replacement = 'num', fixed = TRUE) %>%\n",
    "    gsub(pattern = '%', replacement = 'pct', fixed = TRUE) %>%\n",
    "    gsub(pattern = '(', replacement = '', fixed = TRUE) %>% \n",
    "    gsub(pattern = ')', replacement = '', fixed = TRUE) %>% \n",
    "    gsub(pattern = '-_', replacement = '', fixed = TRUE) %>%\n",
    "    gsub(pattern = '+', replacement = '', fixed = TRUE) %>% \n",
    "    gsub(pattern = '-', replacement = '_', fixed = TRUE)\n",
    "\n",
    "  return(columns)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample Data Manipulation Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a copy of the data.table to make check transformations in next step\n",
    "d_input_in <- d_input\n",
    "\n",
    "# set new column names\n",
    "setnames(x = d_input, old = names(d_input), new = fixNames(names(d_input))) \n",
    "\n",
    "#----- Data Cleaning (Specific to BU) ------\n",
    "# !!! temporary step\n",
    "# pre-processing removes \"Global\" entry under the \"type_of_account\" field since it isn't an option in the template\n",
    "# Currently, only Global-FoS and GLobal-FoE are options, but this is specific to Europe\n",
    "# this step replaces these blanks with \"Global\"\n",
    "\n",
    "\n",
    "d_input[business_unit == 'US' & type_of_account != 'Local', type_of_account := 'Global']\n",
    "d_input[business_partner_name == 'Delta Vacations, LLC', business_partner_name := 'Delta Airlines'] #US had a change in main office; manual correction to the name\n",
    "\n",
    "# fix channel for \"Car Trawler\" for all BUs\n",
    "d_input[business_partner_name == 'Car Trawler', distribution_channel := 'Online Travel Agencies (OTAs)']\n",
    "\n",
    "# change \"Other\" in Switzerland's channel and sublob to \"Not Provided\"\n",
    "d_input[business_unit == 'CH' & distribution_channel %in% c('', 'Other'), distribution_channel := 'Not Provided']\n",
    "d_input[business_unit == 'CH' & sub_lob == 'Other', sub_lob := 'Not Provided']\n",
    "\n",
    "# Fix some of the characters for b-partners that got distorted in pre-processing\n",
    "d_input[business_partner_name == 'CornÃ¨r Banca', business_partner_name := 'Cornèr Banca']\n",
    "d_input[business_partner_name == 'ESL SÃ©jours Linguistiques', business_partner_name := 'ESL Séjours Linguistiques']\n",
    "d_input[business_partner_name == 'ReisebÃ¼ro Mittelthurgau', business_partner_name := 'Reisebüro Mittelthurgau']\n",
    "d_input[business_partner_name == 'Ã–KK', business_partner_name := 'ÖKK']\n",
    "d_input[business_partner_name == 'HK fÃ¼r GÃ¤ste', business_partner_name := 'HK für Gäste']\n",
    "d_input[business_partner_name == 'Twerenbold â€“ Busreisen Assistance Europa', business_partner_name := 'Twerenbold Busreisen Assistance Europa']\n",
    "d_input[business_partner_name == 'VÃ¶gele Reisen', business_partner_name := 'Vögele Reisen']\n",
    "d_input[business_partner_name == 'Last Minute Tours RestplatzbÃ¶rse', business_partner_name := 'Last Minute Tours Restplatzbörse']\n",
    "d_input[business_partner_name == 'InterdiÃ¶zesane Lourdeswallfahrt', business_partner_name := 'Interdiözesane Lourdeswallfahrt']\n",
    "d_input[business_partner_name == 'StÃ¶cklin Reisen', business_partner_name := 'Stöcklin Reisen']\n",
    "d_input[business_partner_name == 'Heilungskosten fÃ¼r GÃ¤ste', business_partner_name := 'Heilungskosten für Gäste']\n",
    "d_input[business_partner_name == 'Tourasia RÃ¶mer', business_partner_name := 'Tourasia Römer']\n",
    "d_input[business_partner_name == 'Sumiswalder GrundgebÃ¼hr', business_partner_name := 'Sumiswalder Grundgebühr']\n",
    "\n",
    "\n",
    "\n",
    "#----- Add currency conversion to raw data ------\n",
    "# define columns that will need a conversion\n",
    "curr_cols <- c(\n",
    " 'written_revenues_net_of_taxes',\n",
    " 'written_revenues',\n",
    " 'earned_revenues_net_of_taxes',\n",
    "'earned_revenues',\n",
    " 'earned_base_commissions',\n",
    " 'earned_over_commissions',\n",
    " 'upfront_cash_payments',\n",
    " 'total_compensation',\n",
    " 'paid_claims',\n",
    " 'actual_incurred_losses',\n",
    " 'internal_variable_costs',\n",
    " 'az_tech_fee',\n",
    " 'internal_fixed_costs',\n",
    " 'hq_fees',\n",
    " 'total_expenses',\n",
    " 'severity',\n",
    " 'risk_premium',\n",
    " 'cm_bu_view',\n",
    " 'cm_hq_view',\n",
    " 'profit_or_loss'\n",
    ")\n",
    "\n",
    "# replace existing China in main dataset\n",
    "d <- rbindlist(list(d_input), use.names = TRUE, fill = TRUE)\n",
    "\n",
    "#----- addtl TEMP data manipulation ------\n",
    "\n",
    "\n",
    "#----- Data Cleaning ------\n",
    "\n",
    "\n",
    "# save copy of data to manipulate\n",
    "d <- d_input\n",
    "\n",
    "# replace all NAs with 0s\n",
    "replaceNA(d)\n",
    "\n",
    "# additional manipulations\n",
    "# change unknown channels and sublobs to \"Other\"\n",
    "# ! now completed in pre-processing\n",
    "#d[distribution_channel == '0', distribution_channel := 'Other']\n",
    "#d[sub_lob == '0', sub_lob := 'Other']\n",
    "\n",
    "# add bu names to dataset\n",
    "# rename \"Scandinavia\" to \"Scandinavia/Baltics\" (more inclusive of the dataset)\n",
    "# changed upstream in process\n",
    "#i_bu[BU_CODE == 'SC', BU_DESCR := 'Scandinavia/Baltics']\n",
    "\n",
    "## test\n",
    "d <- merge(d, i_bu[, .(BU_CODE, bu_descr = BU_DESCR)], by.x = 'business_unit', by.y = 'BU_CODE', all.x = TRUE)\n",
    "\n",
    "\n",
    "# Fix text in fields\n",
    "\n",
    "d[product_name %in% c('0', '', '-'), product_name := 'Not Provided']\n",
    "d[business_partner_name %in% c('-', '0', ''), business_partner_name := 'Not Provided']\n",
    "\n",
    "\n",
    "# Add a reporting period and combined date of analysis\n",
    "# F version: changed from \"min\" to \"max\"\n",
    "# !!! special case for CN with different format\n",
    "#d[business_unit == 'CN', \n",
    "#  month_of_analysis_max := format(as.Date(max(as.numeric(date_of_analysis)), \n",
    "#                                            origin = '1899-12-30'), '%Y %b'), \n",
    "#  by = business_unit]\n",
    "\n",
    "d[,  month_of_analysis_max := format(as.Date(max(date_of_analysis)), '%Y %b'),  by = business_unit]\n",
    "\n",
    "#d[,  month_of_analysis_max := max(date_of_analysis),  by = business_unit]\n",
    "\n",
    "#d[business_unit == 'CN',\n",
    "#  reporting_period := paste(\n",
    "#  format(as.Date(as.numeric(reporting_date_from), origin = '1899-12-30'), '%Y %b'),\n",
    "#  'to',\n",
    "#  format(as.Date(as.numeric(reporting_date_to), origin = '1899-12-30'), '%Y %b')\n",
    "#  )]\n",
    "\n",
    "d[, \n",
    "  reporting_period := paste(\n",
    "  format(as.Date(reporting_date_from), '%Y %b'),\n",
    "  'to',\n",
    "  format(as.Date(reporting_date_to), '%Y %b')\n",
    "  )]\n",
    "\n",
    "# Replace LoB column with \"Travel\" since some show up blank or NA\n",
    "d[, lob := 'Travel']\n",
    "\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Compare the original data.table to the transformed version, example to be built upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Compare d_input_in to d_input, should be no transformations.\")\n",
    "\n",
    "comparedf(d_input_in, d_input)\n",
    "\n",
    "print(\"Compare d_input to d, should be all transformations.\")\n",
    "comparedf(d, d_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Output a tempfile to be turned into final outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_parquet(d, tempfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}