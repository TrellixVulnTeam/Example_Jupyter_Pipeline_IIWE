{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/AzPTravel_PPM.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Source File Consolidation\n",
    "\n",
    "#### This script fetches the current data collection submission files, consolidates them in to a combined csv file, and outputs that to the network.\n",
    "- All source files stored in the path are read, summarized, and then consolidated into a single dataframe named 'df'.\n",
    "- This process assumes that the multiple sources are in no way duplicates of each other.\n",
    "- df is then output in the data collection subfolder of the \"Production\" folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Variables\n",
    "- These are overwritten if inherited from run_control.ipynb.\n",
    "- Feel Free to reset them for a manual run if you like\n",
    "- Do not save without percode = \"-f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "commit_message = \"Development and testing.\"\n",
    "# Give a brief reason for the run.\n",
    "\n",
    "run_control = 1\n",
    "#run_type = 0 - Lite run with no reporting, not recommended.\n",
    "#run_type = 1 - Lite run with normal reporting, default setting.\n",
    "#run_type = 2 - Heavy run with full reporting, available for audits and troubleshooting.\n",
    "#run_type = 5 - A default setting. Indicates the script is being run by an outside process without an inherited value\n",
    "\n",
    "percode = \"2021.Q1\"\n",
    "# Data Collection Code, this controls file paths and output names\n",
    "# \"-f\" is the value indicating a bad inheritance from run with arg\n",
    "\n",
    "#----------\n",
    "# do not edit - this either inherits the full instance timestamp from the papermill book or captures the run time of this script.\n",
    "from datetime import datetime\n",
    "inst_datetime = datetime.now().strftime(\"%m%d%Y%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os # System commands\n",
    "import sys # System commands\n",
    "\n",
    "import getpass # parquet file read/write\n",
    "import json # json file read/write\n",
    "from sklearn import datasets # pass vars between .ipynb s\n",
    "\n",
    "import matplotlib.pyplot as plt #Plots and Graphs\n",
    "import pandas as pd #DataFrame and math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default Variables, these govern logic, do not edit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "default_dc = \"20XX.QX\"\n",
    "default_rc = 0 #extra lite mode\n",
    "dummy_perc = \"33Q3\" # bad inheritance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Script determining run context ie, manual, run_control.ipynb, or other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "if run_control == 5:\n",
    "    run_control = default_rc \n",
    "else:\n",
    "    run_control = run_control\n",
    "\n",
    "try:\n",
    "    if sys.argv[1] == \"-f\":\n",
    "        percode = percode\n",
    "    else:\n",
    "        percode = sys.argv[1]\n",
    "\n",
    "except IndexError:\n",
    "    percode = default_dc\n",
    "except NameError:\n",
    "    percode = default_dc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### style settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Make paths for the source folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rt_path = f'//hecate/Insurance_US/Product Development/Product Management/Global PPM/Reporting/Data Collection/Production/{str(percode)}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Read each json file into temp DataFrame \"data\".\n",
    "- Prep actions - Strip (trim) leading and trailing spaces values in string columns, remove rows without business units.\n",
    "- Append each json output to into 1 DataFrame \"df\".\n",
    "- Process Cleanup, the indices restart with each append, reset and drop the previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Passed non-file path: //hecate/Insurance_US/Product Development/Product Management/Global PPM/Reporting/Data Collection/Production/2021.Q1\\2021.Q1prep.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d7e14150274d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprepparq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrt_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"{percode}prep.parquet\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprepparq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"pyarrow\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprepfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, **kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \"\"\"\n\u001b[0;32m    316\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, path, columns, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"use_pandas_metadata\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         result = self.api.parquet.read_table(\n\u001b[1;32m--> 142\u001b[1;33m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m         ).to_pandas()\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyarrow\\parquet.py\u001b[0m in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, metadata, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size)\u001b[0m\n\u001b[0;32m   1272\u001b[0m                             \u001b[0mread_dictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_dictionary\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m                             \u001b[0mbuffer_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1274\u001b[1;33m                             filesystem=filesystem, filters=filters)\n\u001b[0m\u001b[0;32m   1275\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m         pf = ParquetFile(source, metadata=metadata,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyarrow\\parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_paths, filesystem, schema, metadata, split_row_groups, validate_schema, filters, metadata_nthreads, read_dictionary, memory_map, buffer_size)\u001b[0m\n\u001b[0;32m   1028\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_manifest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m              \u001b[0mpath_or_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata_nthreads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata_nthreads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m              \u001b[0mopen_file_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_dataset_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m         )\n\u001b[0;32m   1032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyarrow\\parquet.py\u001b[0m in \u001b[0;36m_make_manifest\u001b[1;34m(path_or_paths, fs, pathsep, metadata_nthreads, open_file_func)\u001b[0m\n\u001b[0;32m   1227\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m                 raise IOError('Passed non-file path: {0}'\n\u001b[1;32m-> 1229\u001b[1;33m                               .format(path))\n\u001b[0m\u001b[0;32m   1230\u001b[0m             \u001b[0mpiece\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParquetDatasetPiece\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen_file_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen_file_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m             \u001b[0mpieces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpiece\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Passed non-file path: //hecate/Insurance_US/Product Development/Product Management/Global PPM/Reporting/Data Collection/Production/2021.Q1\\2021.Q1prep.parquet"
     ]
    }
   ],
   "source": [
    "prepfile = os.path.join(str(rt_path), f\"{percode}prep.csv\")\n",
    "prepparq = os.path.join(str(rt_path), f\"{percode}prep.parquet\")\n",
    "\n",
    "df = pd.read_parquet(prepparq, engine = \"pyarrow\")\n",
    "\n",
    "os.remove(prepfile)\n",
    "os.remove(prepparq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Upload Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def num_format(x):\n",
    "    \"\"\"number format without a currency\"\"\"\n",
    "    return \"{:,.0f}\".format(x)\n",
    "\n",
    "if run_control > 0:\n",
    "\n",
    "    sumdata = df.groupby(['Business Unit']).sum()\n",
    "    sumdata = sumdata.reset_index()\n",
    "    plt.bar(sumdata['Business Unit'], sumdata['Earned Revenues net of Taxes']/1000)\n",
    "    plt.title('Earned Revenue net of Taxes by BU in thousands LC')\n",
    "    plt.show()\n",
    "\n",
    "    countdata = df.groupby(['Business Unit']).count()\n",
    "    countdata = countdata.reset_index()\n",
    "    plt.bar(countdata['Business Unit'], countdata['Earned Revenues net of Taxes'])\n",
    "    plt.title('Row Counts by BU')\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Charts Skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw files - extensive audit, best to skip unless troubleshooting, may crash a browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# setup for json only\n",
    "# if run_control > 1:\n",
    "#     for f in pathfiles:\n",
    "#         with open(f, 'r') as json_file:\n",
    "#             json_object = json.load(json_file)\n",
    "#         print(json.dumps(json_object, indent=1))\n",
    "#\n",
    "# else:\n",
    "#     print(\"Audit Report 1 Skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Processes\n",
    "- Define File names.\n",
    "- If existing csv is found, archive it in \"raw_data_file_history\" folder.\n",
    "- Save new csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file = f'{str(percode)}.csv'\n",
    "pfile = f'{str(percode)}.parquet'\n",
    "histfile = f'{str(percode)}_{inst_datetime}.csv'\n",
    "\n",
    "try:\n",
    "    os.rename(os.path.join(str(rt_path), file), os.path.join(str(rt_path), \"logs/raw_data_file_history/\" , histfile))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "df.to_csv(os.path.join(str(rt_path), file), ',', index=False , encoding='utf-8-sig')\n",
    "df.to_parquet(os.path.join(str(rt_path), pfile), engine = \"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Log update record with commit message and time.\n",
    "- Determine commit message and make new entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log = os.path.join(str(rt_path), f'logs/pipline_log.csv' )\n",
    "\n",
    "try:\n",
    "    log_df = pd.read_csv(log)\n",
    "except NameError:\n",
    "    print(\"No log file present\")\n",
    "\n",
    "# determine if running from notebook or Excel controller and set commit message.\n",
    "if sys.argv[1] == \"-f\":\n",
    "    message = commit_message\n",
    "else:\n",
    "    piperunner = '//hecate/Insurance_US/Product Development/Product Management/Global PPM/Reporting/_To' \\\n",
    "                 'ols/GitHub/Production Repositories/Pipeline Runner/Pipeline Runner.xlsm'\n",
    "    wb = openpyxl.load_workbook(piperunner)\n",
    "    sh = wb['Pipeline Runner']\n",
    "    message = sh['f13'].value\n",
    "\n",
    "# find username\n",
    "username = getpass.getuser()\n",
    "\n",
    "# record timestamp\n",
    "datetime = inst_datetime\n",
    "dateformat = datetime[4:8] + '-' + datetime[:2]  + '-' + datetime[2:4]  + '-' + datetime[8:]\n",
    "\n",
    "# add new line\n",
    "newline = { \"run_message\" : [message ],  \"datetime\" :[dateformat], \"user\" : [username ]}\n",
    "newline = pd.DataFrame.from_dict(newline)\n",
    "\n",
    "# make new file\n",
    "log_df = log_df.append(newline[0:])\n",
    "log_df\n",
    "log_df.to_csv(log, ',', index=False , encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the DataFrame for other noteboks to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dc_df = df\n",
    "\n",
    "%store read_dc_df\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
